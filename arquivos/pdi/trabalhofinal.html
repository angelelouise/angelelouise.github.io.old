<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<!--[if IE]><meta http-equiv="X-UA-Compatible" content="IE=edge"><![endif]-->
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 1.5.5.dev">
<meta name="author" content="Victor Mafra e Angele Louise">
<title>APLICATIVO ANDROID DE DETECÇÃO E RASTREAMENTO DE FACE HUMANA EM TEMPO REAL UTILIZANDO OPENCV</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700">
<style>
/* Asciidoctor default stylesheet | MIT License | http://asciidoctor.org */
/* Remove comment around @import statement below when using as a custom stylesheet */
/*@import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700";*/
article,aside,details,figcaption,figure,footer,header,hgroup,main,nav,section,summary{display:block}
audio,canvas,video{display:inline-block}
audio:not([controls]){display:none;height:0}
[hidden],template{display:none}
script{display:none!important}
html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}
body{margin:0}
a{background:transparent}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
abbr[title]{border-bottom:1px dotted}
b,strong{font-weight:bold}
dfn{font-style:italic}
hr{-moz-box-sizing:content-box;box-sizing:content-box;height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type="button"],input[type="reset"],input[type="submit"]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type="checkbox"],input[type="radio"]{box-sizing:border-box;padding:0}
input[type="search"]{-webkit-appearance:textfield;-moz-box-sizing:content-box;-webkit-box-sizing:content-box;box-sizing:content-box}
input[type="search"]::-webkit-search-cancel-button,input[type="search"]::-webkit-search-decoration{-webkit-appearance:none}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,*:before,*:after{-moz-box-sizing:border-box;-webkit-box-sizing:border-box;box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;font-weight:400;font-style:normal;line-height:1;position:relative;cursor:auto}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
body{-webkit-font-smoothing:antialiased}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.center{margin-left:auto;margin-right:auto}
.spread{width:100%}
p.lead,.paragraph.lead>p,#preamble>.sectionbody>.paragraph:first-of-type p{font-size:1.21875em;line-height:1.6}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0;direction:ltr}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:none}
p{font-family:inherit;font-weight:400;font-size:1em;line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #ddddd8;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em;height:0}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{font-size:1em;line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol,ul.no-bullet,ol.no-bullet{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0;font-size:1em}
ul.square li ul,ul.circle li ul,ul.disc li ul{list-style:inherit}
ul.square{list-style-type:square}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ul.no-bullet{list-style:none}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
abbr,acronym{text-transform:uppercase;font-size:90%;color:rgba(0,0,0,.8);border-bottom:1px dotted #ddd;cursor:help}
abbr{text-transform:none}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote cite{display:block;font-size:.9375em;color:rgba(0,0,0,.6)}
blockquote cite:before{content:"\2014 \0020"}
blockquote cite a,blockquote cite a:visited{color:rgba(0,0,0,.6)}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media only screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:solid 1px #dedede}
table thead,table tfoot{background:#f7f8f7;font-weight:bold}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt,table tr:nth-of-type(even){background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{display:table-cell;line-height:1.6}
body{tab-size:4}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.clearfix:before,.clearfix:after,.float-group:before,.float-group:after{content:" ";display:table}
.clearfix:after,.float-group:after{clear:both}
*:not(pre)>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background-color:#f7f7f8;-webkit-border-radius:4px;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed}
pre,pre>code{line-height:1.45;color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;text-rendering:optimizeSpeed}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background-color:#f7f7f7;border:1px solid #ccc;-webkit-border-radius:3px;border-radius:3px;-webkit-box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em white inset;box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em #fff inset;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menu{color:rgba(0,0,0,.8)}
b.button:before,b.button:after{position:relative;top:-1px;font-weight:400}
b.button:before{content:"[";padding:0 3px 0 2px}
b.button:after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin-left:auto;margin-right:auto;margin-top:0;margin-bottom:0;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header:before,#header:after,#content:before,#content:after,#footnotes:before,#footnotes:after,#footer:before,#footer:after{content:" ";display:table}
#header:after,#content:after,#footnotes:after,#footer:after{clear:both}
#content{margin-top:1.25em}
#content:before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #ddddd8}
#header>h1:only-child,body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #ddddd8;padding-bottom:8px}
#header .details{border-bottom:1px solid #ddddd8;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:-ms-flexbox;display:-webkit-flex;display:flex;-ms-flex-flow:row wrap;-webkit-flex-flow:row wrap;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span:before{content:"\00a0\2013\00a0"}
#header .details br+span.author:before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark:before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber:after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #ddddd8;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #efefed;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media only screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
#toc.toc2{margin-top:0!important;background-color:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #efefed;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #efefed;left:auto;right:0}}
@media only screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border-style:solid;border-width:1px;border-color:#e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;-webkit-border-radius:4px;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:100%;background-color:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:rgba(255,255,255,.8);line-height:1.44}
.sect1{padding-bottom:.625em}
@media only screen and (min-width:768px){.sect1{padding-bottom:1.25em}}
.sect1+.sect1{border-top:1px solid #efefed}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor:before,h2>a.anchor:before,h3>a.anchor:before,#toctitle>a.anchor:before,.sidebarblock>.content>.title>a.anchor:before,h4>a.anchor:before,h5>a.anchor:before,h6>a.anchor:before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock>caption.title{white-space:nowrap;overflow:visible;max-width:0}
.paragraph.lead>p,#preamble>.sectionbody>.paragraph:first-of-type p{color:rgba(0,0,0,.85)}
table.tableblock #preamble>.sectionbody>.paragraph:first-of-type p{font-size:inherit}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #ddddd8;color:rgba(0,0,0,.6)}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border-style:solid;border-width:1px;border-color:#e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;-webkit-border-radius:4px;border-radius:4px}
.exampleblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child{margin-bottom:0}
.sidebarblock{border-style:solid;border-width:1px;border-color:#e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;-webkit-border-radius:4px;border-radius:4px}
.sidebarblock>:first-child{margin-top:0}
.sidebarblock>:last-child{margin-bottom:0}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock pre:not(.highlight),.listingblock pre[class="highlight"],.listingblock pre[class^="highlight "],.listingblock pre.CodeRay,.listingblock pre.prettyprint{background:#f7f7f8}
.sidebarblock .literalblock pre,.sidebarblock .listingblock pre:not(.highlight),.sidebarblock .listingblock pre[class="highlight"],.sidebarblock .listingblock pre[class^="highlight "],.sidebarblock .listingblock pre.CodeRay,.sidebarblock .listingblock pre.prettyprint{background:#f2f1f1}
.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{-webkit-border-radius:4px;border-radius:4px;word-wrap:break-word;padding:1em;font-size:.8125em}
.literalblock pre.nowrap,.literalblock pre[class].nowrap,.listingblock pre.nowrap,.listingblock pre[class].nowrap{overflow-x:auto;white-space:pre;word-wrap:normal}
@media only screen and (min-width:768px){.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{font-size:.90625em}}
@media only screen and (min-width:1280px){.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{font-size:1em}}
.literalblock.output pre{color:#f7f7f8;background-color:rgba(0,0,0,.9)}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;-webkit-border-radius:4px;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.listingblock>.content{position:relative}
.listingblock code[data-lang]:before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:#999}
.listingblock:hover code[data-lang]:before{display:block}
.listingblock.terminal pre .command:before{content:attr(data-prompt);padding-right:.5em;color:#999}
.listingblock.terminal pre .command:not([data-prompt]):before{content:"$"}
table.pyhltable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.pyhltable td{vertical-align:top;padding-top:0;padding-bottom:0;line-height:1.45}
table.pyhltable td.code{padding-left:.75em;padding-right:0}
pre.pygments .lineno,table.pyhltable td:not(.code){color:#999;padding-left:0;padding-right:.5em;border-right:1px solid #ddddd8}
pre.pygments .lineno{display:inline-block;margin-right:.25em}
table.pyhltable .linenodiv{background:none!important;padding-right:0!important}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock blockquote p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote:before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.5em;margin-right:.5ex;text-align:right}
.quoteblock .quoteblock{margin-left:0;margin-right:0;padding:.5em 0;border-left:3px solid rgba(0,0,0,.6)}
.quoteblock .quoteblock blockquote{padding:0 0 0 .75em}
.quoteblock .quoteblock blockquote:before{display:none}
.verseblock{margin:0 1em 1.25em 1em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract{margin:0 0 1.25em 0;display:block}
.quoteblock.abstract blockquote,.quoteblock.abstract blockquote p{text-align:left;word-spacing:0}
.quoteblock.abstract blockquote:before,.quoteblock.abstract blockquote p:first-of-type:before{display:none}
table.tableblock{max-width:100%;border-collapse:separate}
table.tableblock td>.paragraph:last-child p>p:last-child,table.tableblock th>p:last-child,table.tableblock td>p:last-child{margin-bottom:0}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all th.tableblock,table.grid-all td.tableblock{border-width:0 1px 1px 0}
table.grid-all tfoot>tr>th.tableblock,table.grid-all tfoot>tr>td.tableblock{border-width:1px 1px 0 0}
table.grid-cols th.tableblock,table.grid-cols td.tableblock{border-width:0 1px 0 0}
table.grid-all *>tr>.tableblock:last-child,table.grid-cols *>tr>.tableblock:last-child{border-right-width:0}
table.grid-rows th.tableblock,table.grid-rows td.tableblock{border-width:0 0 1px 0}
table.grid-all tbody>tr:last-child>th.tableblock,table.grid-all tbody>tr:last-child>td.tableblock,table.grid-all thead:last-child>tr>th.tableblock,table.grid-rows tbody>tr:last-child>th.tableblock,table.grid-rows tbody>tr:last-child>td.tableblock,table.grid-rows thead:last-child>tr>th.tableblock{border-bottom-width:0}
table.grid-rows tfoot>tr>th.tableblock,table.grid-rows tfoot>tr>td.tableblock{border-width:1px 0 0 0}
table.frame-all{border-width:1px}
table.frame-sides{border-width:0 1px}
table.frame-topbot{border-width:1px 0}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{display:table-cell;line-height:1.6;background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
td>div.verse{white-space:pre}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
ol>li p,ul>li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.unstyled,ol.unnumbered,ul.checklist,ul.none{list-style-type:none}
ul.unstyled,ol.unnumbered,ul.checklist{margin-left:.625em}
ul.checklist li>p:first-child>.fa-square-o:first-child,ul.checklist li>p:first-child>.fa-check-square-o:first-child{width:1em;font-size:.85em}
ul.checklist li>p:first-child>input[type="checkbox"]:first-child{width:1em;position:relative;top:1px}
ul.inline{margin:0 auto .625em auto;margin-left:-1.375em;margin-right:0;padding:0;list-style:none;overflow:hidden}
ul.inline>li{list-style:none;float:left;margin-left:1.375em;display:block}
ul.inline>li>*{display:block}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist>table tr>td:first-of-type{padding:0 .75em;line-height:1}
.colist>table tr>td:last-of-type{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:solid 4px #fff;-webkit-box-shadow:0 0 0 1px #ddd;box-shadow:0 0 0 1px #ddd}
.imageblock.left,.imageblock[style*="float: left"]{margin:.25em .625em 1.25em 0}
.imageblock.right,.imageblock[style*="float: right"]{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em 0;border-width:1px 0 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;text-indent:-1.05em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
.gist .file-data>table{border:0;background:#fff;width:100%;margin-bottom:0}
.gist .file-data>table td.line-data{width:99%}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background-color:#00fafa}
.black{color:#000}
.black-background{background-color:#000}
.blue{color:#0000bf}
.blue-background{background-color:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background-color:#fa00fa}
.gray{color:#606060}
.gray-background{background-color:#7d7d7d}
.green{color:#006000}
.green-background{background-color:#007d00}
.lime{color:#00bf00}
.lime-background{background-color:#00fa00}
.maroon{color:#600000}
.maroon-background{background-color:#7d0000}
.navy{color:#000060}
.navy-background{background-color:#00007d}
.olive{color:#606000}
.olive-background{background-color:#7d7d00}
.purple{color:#600060}
.purple-background{background-color:#7d007d}
.red{color:#bf0000}
.red-background{background-color:#fa0000}
.silver{color:#909090}
.silver-background{background-color:#bcbcbc}
.teal{color:#006060}
.teal-background{background-color:#007d7d}
.white{color:#bfbfbf}
.white-background{background-color:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background-color:#fafa00}
span.icon>.fa{cursor:default}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note:before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip:before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning:before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution:before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important:before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background-color:rgba(0,0,0,.8);-webkit-border-radius:100px;border-radius:100px;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]:after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,span.alt{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background-color:#fffef7;border-color:#e0e0dc;-webkit-box-shadow:0 1px 4px #e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@media print{@page{margin:1.25cm .75cm}
*{-webkit-box-shadow:none!important;box-shadow:none!important;text-shadow:none!important}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare):after,a[href^="https:"]:not(.bare):after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]:after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #ddddd8!important;padding-bottom:0!important}
.sect1{padding-bottom:0!important}
.sect1+.sect1{border:0!important}
#header>h1:first-child{margin-top:1.25rem}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em 0}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span:before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]:before{display:block}
#footer{background:none!important;padding:0 .9375em}
#footer-text{color:rgba(0,0,0,.6)!important;font-size:.9em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
</style>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css">
</head>
<body class="article toc2 toc-left">
<div id="header">
<h1>APLICATIVO ANDROID DE DETECÇÃO E RASTREAMENTO DE FACE HUMANA EM TEMPO REAL UTILIZANDO OPENCV</h1>
<div class="details">
<span id="author" class="author">Victor Mafra e Angele Louise</span><br>
<span id="email" class="email">&lt;<a href="mailto:angelealst@hotmail.com">angelealst@hotmail.com</a> e <a href="mailto:vick.vems@gmail.com">vick.vems@gmail.com</a>&gt;</span><br>
</div>
<div id="toc" class="toc2">
<div id="toctitle">Table of Contents</div>
<ul class="sectlevel1">
<li><a href="#true1-introdu-o">1. INTRODUÇÃO</a></li>
<li><a href="#true2-programas-e-ferramentas-utilizadas">2. PROGRAMAS E FERRAMENTAS UTILIZADAS</a></li>
<li><a href="#true3-conte-do-te-rico">3. CONTEÚDO TEÓRICO</a>
<ul class="sectlevel2">
<li><a href="#true3-1-algoritmo-de-viola-jones">3.1. ALGORITMO DE VIOLA-JONES</a></li>
<li><a href="#true3-2-classificador-lbp-e-haar-like">3.2. CLASSIFICADOR LBP e Haar-like</a></li>
<li><a href="#true3-3-m-todo-lucas-kanade">3.3. MÉTODO LUCAS-KANADE</a></li>
</ul>
</li>
<li><a href="#true4-estrutura-de-um-aplicativo-android">4. ESTRUTURA DE UM APLICATIVO ANDROID</a></li>
<li><a href="#true5-estrutura-do-projeto">5. ESTRUTURA DO PROJETO</a>
<ul class="sectlevel2">
<li><a href="#true5-1-m-todos-essenciais-sobrepostos-da-activity">5.1. MÉTODOS ESSENCIAIS SOBREPOSTOS DA ACTIVITY</a></li>
<li><a href="#true5-2-m-todos-sobrepostos-da-implementa-o-de-classe-opencv">5.2. MÉTODOS SOBREPOSTOS DA IMPLEMENTAÇÃO DE CLASSE OPENCV</a></li>
<li><a href="#true5-3-an-lise-do-c-digo-de-detec-o-e-rastreio-de-faces">5.3. ANÁLISE DO CÓDIGO DE DETECÇÃO E RASTREIO DE FACES</a></li>
</ul>
</li>
<li><a href="#true6-conclus-es">6. CONCLUSÕES</a></li>
<li><a href="#true7-refer-ncias">7. REFERÊNCIAS</a></li>
<li><a href="#true8-anexos">8. ANEXOS</a></li>
</ul>
</div>
</div>
<div id="content">
<div class="sect1">
<h2 id="true1-introdu-o"><a class="anchor" href="#true1-introdu-o"></a>1. INTRODUÇÃO</h2>
<div class="sectionbody">
<div class="paragraph">
<p>O seguinte trabalho trata sobre experiência realizada em plataforma Android com finalidade de desenvolver um aplicativo para detecção e rastreamento de faces em tempo real utilizando OpenCV(biblioteca multiplataforma de computação visual) para o processamento de vídeo. Para detectar faces foi feito uso de classificadores do tipo LBP e Haar e para o rastreamento o método de Lucas-Kanade, que são recursos oferecidos pela biblioteca supracitada.
Tal trabalho foi feito com o objetivo de adquirir conhecimento na área assim como atender as demandas acadêmicas do terceiro período da disciplina de processamento digital de imagens em 2016.1 do curso de Engenharia de Computação/UFRN.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="true2-programas-e-ferramentas-utilizadas"><a class="anchor" href="#true2-programas-e-ferramentas-utilizadas"></a>2. PROGRAMAS E FERRAMENTAS UTILIZADAS</h2>
<div class="sectionbody">
<div class="paragraph">
<p>O ambiente de desenvolvimento utilizado foi o Android Studio versão 1.5.1, que é o oficial para desenvolvimento em Android. Para o desenvolvimento das funções de reconhecimento e rastreio foram usadas as bibliotecas do OpenCV(API de visão computacional) na versão 2.4.10 baixadas do site. Para o funcionamento do aplicativo no dispositivos foi necessário baixar do Google Play o OpenCV Manager, que são as bibliotecas necessárias para o funcionamento correto dos aplicativos publicados e que fazem uso de funções do OpenCV. Essa dependência existe visando o menor tamanho dos aplicativos, de tal forma que nenhum deles carregam as bibliotecas em seu código. Os testes foram realizados em 3 dispositivos: Tablet Nexus 7, Lenovo A7010 e Morotola Moto G 2ªgen.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="true3-conte-do-te-rico"><a class="anchor" href="#true3-conte-do-te-rico"></a>3. CONTEÚDO TEÓRICO</h2>
<div class="sectionbody">
<div class="paragraph">
<p>O conteúdo desenvolvido no experimento aborda algoritmos já conhecidos para detecção de faces e rastreio. De modo que foram utilizados classificadores do tipo LBP e Haar, assim como método da pirâmide para rastreamento, essa sessão tratara acerca desses algoritmos.</p>
</div>
<div class="sect2">
<h3 id="true3-1-algoritmo-de-viola-jones"><a class="anchor" href="#true3-1-algoritmo-de-viola-jones"></a>3.1. ALGORITMO DE VIOLA-JONES</h3>
<div class="paragraph">
<p>É o primeiro que oferece taxas de detecção de objetos competitivas em tempo real, proposto em 2001 por Paul Viola e Michael Jones. Apesar do algoritmo ter capacidade de receber treinamento para detectar qualquer objeto, seu principal objetivo atualmente é a detecção de faces.
O algoritmo possui uma característica importante, ele apenas distingue as faces das não-faces, ele não as reconhece. Outras características importantes são: a sua robustez, possui uma alta taxa de positivos e uma baixa taxa de falsos positivos e ocorre em tempo real.</p>
</div>
<div class="paragraph">
<p>O algoritmo possui 4 estágios:</p>
</div>
<div class="sect3">
<h4 id="true3-1-1-sele-o-haar-feature"><a class="anchor" href="#true3-1-1-sele-o-haar-feature"></a>3.1.1. Seleção Haar feature:</h4>
<div class="paragraph">
<p>Este método utiliza-se de unidades chamadas <em>features</em> retangulares, eles possuem quatro padrões possíveis e formatos específicos, entretanto podem possuir dimensões e posições arbitrárias dentro de uma janela também arbitrária, o calculo do valor dessas unidades se dá pela diferença entre as somatórias dos <em>pixels</em> na região preta e dos <em>pixels</em> na região branca.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="imagens_final/feature.jpg" alt="feature.jpg">
</div>
<div class="title">Figure 1. Configuração de uma feature.</div>
</div>
<div class="paragraph">
<p><strong>Haar features</strong> partem do pressuposto que todas as faces compartilham de propriedades similares, são elas: A região dos olhos, que é mais escura que a região acima das bochechas; A região do nariz, que é mais clara que a região dos olhos; Localização dos olhos, nariz e boca por proporção.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="imagens_final/face.jpg" alt="face.jpg">
</div>
<div class="title">Figure 2. Sobreposição de features em uma face.</div>
</div>
</div>
<div class="sect3">
<h4 id="true3-1-2-cria-o-de-uma-imagem-integral"><a class="anchor" href="#true3-1-2-cria-o-de-uma-imagem-integral"></a>3.1.2. Criação de uma imagem integral:</h4>
<div class="paragraph">
<p>Para acelerar o cálculo do valor de um feature sobre uma imagem, é necessário usá-la na representação integral, que é o cálculo do somatório de todos os pixels ao redor de um pixel em específico, como pode ser visto na imagem abaixo.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="imagens_final/imagem.jpg" alt="imagem.jpg">
</div>
<div class="title">Figure 3. Imagem integral</div>
</div>
<div class="paragraph">
<p>O valor da imagem integral no ponto 1 é a soma dos pixels de A, enquanto que o ponto 2 é A+B, o ponto 3 é A+C e o ponto 4 é A+B+C+D, portanto a soma dos valores dos pixels do retângulo D pode ser calculada por (4+1) - (2+3).</p>
</div>
</div>
<div class="sect3">
<h4 id="true3-1-3-treinamento-adaboost"><a class="anchor" href="#true3-1-3-treinamento-adaboost"></a>3.1.3. Treinamento AdaBoost:</h4>
<div class="paragraph">
<p>O aprendizado baseado em AdaBoost é utilizado para definir quais das inúmeras features serão utilizadas e também os valores dos limiares a que estarão sujeitas. Esse algoritmo de aprendizado constrói um classificador poderoso através da combinação linear de vários classificadores simples “fracos” ponderados, tal estrutura minimiza a ocorrência de falsos negativos.</p>
</div>
</div>
<div class="sect3">
<h4 id="true3-1-4-classificadores-em-cascata"><a class="anchor" href="#true3-1-4-classificadores-em-cascata"></a>3.1.4. Classificadores em cascata:</h4>
<div class="paragraph">
<p>Estes classificadores são distribuídos em forma de cascata, onde cada nível possui uma quantidade de classificadores fortes. Seu uso torna a detecção de não-faces mais rápida, acelerando a execução do algoritmo.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="imagens_final/cascata.jpg" alt="cascata.jpg">
</div>
<div class="title">Figure 4. Estrutura que representa o detector em cascata.</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="true3-2-classificador-lbp-e-haar-like"><a class="anchor" href="#true3-2-classificador-lbp-e-haar-like"></a>3.2. CLASSIFICADOR LBP e Haar-like</h3>
<div class="paragraph">
<p>O LBP e Haar-like são descritores de textura e forma, que ao serem combinados com classificadores de modo sequencial proporcionam um classificador com baixa taxa de erro.
Feições Haar-like, como visto no tópico anterior, são filtros em que se deve subtrair as regiões positivas (brancas) das negativas (pretas) para se obter um valor que é posteriormente utilizado na categorização das sub-regiões de uma determinada imagem.
LBP ou Local Binary Pattern, define a textura como uma função de variação espacial na intensidade dos pixels de uma imagem, a idéia desse operador é que feições comuns podem ser representadas através de um valor de uma determinada escala númerica, portanto com um conjunto de valores extraídos é possível fazer o reconhecimento de um determinado objeto em uma imagem.
O treinamento e classificação de ambas as abordagens são similares.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="imagens_final/LBP.jpg" alt="LBP.jpg">
</div>
<div class="title">Figure 5. Fase de classificação das abordagens Haar e LBP em cascata.</div>
</div>
</div>
<div class="sect2">
<h3 id="true3-3-m-todo-lucas-kanade"><a class="anchor" href="#true3-3-m-todo-lucas-kanade"></a>3.3. MÉTODO LUCAS-KANADE</h3>
<div class="paragraph">
<p>Foi desenvolvido por Bruce D. Lucas e Takeo Kanade em 1981, é um método diferencial usado para estimativa de fluxo óptico.
Ele avalia a movimentação de pontos em uma pequena janela ao redor do ponto de interesse. É um método não interativo que assume um fluxo óptico constante local, constância de brilho, pequenos movimentos e coerência espacial. Sua abordagem consiste em dividir a imagem em janelas e calcular se os pixels deslocaram de lugar entre as janelas.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="true4-estrutura-de-um-aplicativo-android"><a class="anchor" href="#true4-estrutura-de-um-aplicativo-android"></a>4. ESTRUTURA DE UM APLICATIVO ANDROID</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Há pelo menos 3 camadas distintas que funcionam juntas para o funcionamento do aplicativo. Dentre os três, dois são arquivos xml. O primeiro arquivo xml, chamado <strong>manifest</strong>, é responsável por informar ao sistema quais os componentes do aplicativo e quais as permissões que o mesmo pode ter junto ao sistema. Por exemplo, o trecho <strong>&lt;uses-permission android:name="android.permission.CAMERA"/&gt;</strong> da permissão ao aplicativo de fazer uso das câmeras do dispositivo. O segundo arquivo xml é o de Layout, que respalda as componentes do aplicativo e é responsável pela configuração e organização dos elementos de interação com o usuário. É possível construir o layout inteiramente através de código no arquivo xml com mecanismos de ajuda como autocomplete, assim como o mesmo pode ser suprimido e a codificação ser feita na componente principal em Java. Há ainda a possibilidade de montar o layout com a ajuda de blocos na sessão Design, puxando e arrastando os componentes para a área de layout, dessa forma o código é gerado no arquivo de layout automaticamente.</p>
</div>
<div class="paragraph">
<p>A camada de controle é o componente fundamental de estrutura que define o aplicativo. É codificado em Java e rege os comportamentos e ações presentes no aplicativo.</p>
</div>
<div class="paragraph">
<p>Há quatro tipos diferentes de componentes de aplicativo. Cada tipo tem uma finalidade distinta e tem um ciclo de vida específico que define a forma pela qual o componente é criado e destruído.</p>
</div>
<div class="paragraph">
<p>As componentes são:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Uma atividade é implementada como uma subclasse de <strong>Activity</strong>.</p>
</li>
<li>
<p>Um serviço é implementado como uma subclasse de <strong>Service</strong>.</p>
</li>
<li>
<p>Um provedor de conteúdo é implementado como uma subclasse de <strong>ContentProvider</strong> e precisa implementar um conjunto padrão de APIs que permitem a outros aplicativos realizar transações.</p>
</li>
<li>
<p>Os receptores de transmissão são implementados como subclasses de <strong>BroadcastReceiver</strong>.</p>
</li>
</ul>
</div>
<div class="imageblock">
<div class="content">
<img src="imagens_final/img1.jpg" alt="img1.jpg">
</div>
<div class="title">Figure 6. 1- Arquivo manifest; 2 - arquivo java; 3 - arquivos de layout.</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="true5-estrutura-do-projeto"><a class="anchor" href="#true5-estrutura-do-projeto"></a>5. ESTRUTURA DO PROJETO</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Basicamente a estrutura do aplicativo se dá em métodos essenciais já existentes das classes utilizadas que foram sobrepostos para fim específico da aplicação e métodos secundários auxiliares.</p>
</div>
<div class="sect2">
<h3 id="true5-1-m-todos-essenciais-sobrepostos-da-activity"><a class="anchor" href="#true5-1-m-todos-essenciais-sobrepostos-da-activity"></a>5.1. MÉTODOS ESSENCIAIS SOBREPOSTOS DA ACTIVITY</h3>
<div class="paragraph">
<p>O componente utilizado no experimento foi do tipo Activity. Basicamente em toda atividade há interação com o usuário, portanto torna-se mandatório a configuração de dados e tela a serem exibidos, dessa forma alguns métodos extremamente funcionais às atividades foram sobrepostos. São eles: <strong>onDestroy()</strong>, <strong>onCreate(Bundle)</strong>, <strong>onPause()</strong>, <strong>onResume()</strong>.
No método <strong>onCreate(Bundle)</strong> toda a atividade será inicializada e configurada, junto com as informações de tela. O conteúdo a ser mostrado ao usuário que está configurado no arquivo xml é setado no método <strong>setContextView(view)</strong>.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="imagens_final/view1.jpg" alt="view1.jpg">
</div>
<div class="title">Figure 7. Componente JavaCameraView no arquivo de Layout</div>
</div>
<div class="paragraph">
<p>A ponte entre a classe nativa de câmera utilizada pelo sistema e a classe de câmera da biblioteca do OpenCV é identificada no arquivo de Layout através do identificador “R.id.java_surface_view” da componente <strong>JavaCameraView</strong>.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="imagens_final/oncreate.jpg" alt="oncreate.jpg">
</div>
<div class="title">Figure 8. Trechos destacados apresentam respectivamente a função onde o Layout é setado e JavaCameraView sendo alocado em variável.</div>
</div>
<div class="paragraph">
<p>Os métodos <strong>onPause()</strong>, <strong>onResume()</strong> e <strong>onDestroy()</strong> funcionam respectivamente para pausar a aplicação quando o usuário o deixa em segundo plano, retornar a atividade que estava em segundo plano e destruir a atividade, terminando completamente a execução do aplicativo.</p>
</div>
</div>
<div class="sect2">
<h3 id="true5-2-m-todos-sobrepostos-da-implementa-o-de-classe-opencv"><a class="anchor" href="#true5-2-m-todos-sobrepostos-da-implementa-o-de-classe-opencv"></a>5.2. MÉTODOS SOBREPOSTOS DA IMPLEMENTAÇÃO DE CLASSE OPENCV</h3>
<div class="paragraph">
<p>Com o propósito de manipular os frames da filmagem antes deles serem mostrados ao usuário fez-se necessário que a classe principal implementasse a interface <strong>CvCameraViewListener2</strong>, que se comunica com o <strong>JavaCameraView</strong> e possibilita a obtenção dos quadros RGBA(quadros coloridos em canais vermelho, verde, azul e transparência, cuja variável é <strong>mRgba</strong>) obtidos e também a versão em escala de cinza(variável <strong>mGray</strong>) dos mesmos.
Essa interface oferece três métodos <strong>onCameraViewStarted(int, int)</strong>, <strong>onCameraViewStopped() </strong>e <strong>onCameraFrame(CvCameraViewFrame)</strong>. No primeiro método são passados por parâmetro os tamanhos de quadro para que as matrizes e variáveis possam ser inicializadas. Isso acontece quando o preview da câmera é iniciado.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="imagens_final/oncameraviewstarted.jpg" alt="oncameraviewstarted.jpg">
</div>
<div class="title">Figure 9. Imagem do código do método onCameraView e suas dependencias.</div>
</div>
<div class="paragraph">
<p>O segundo método libera as matrizes dos quadros e é chamada quando o preview não se faz mais necessário.
O terceiro método é onde as ações do aplicativo ocorrem. Tal função passa por parâmetro o <strong>inputFrame</strong>, que é o frame capturado via câmera do dispositivo e após manipulação retorna o frame para ser visualizado no preview pelo usuário na componente <strong>JavaCameraView</strong> localizado no Layout. Basicamente 90% do comportamento e ações do aplicativo advém da codificação inserida nesse método, que será discutida nas sessões seguintes.</p>
</div>
</div>
<div class="sect2">
<h3 id="true5-3-an-lise-do-c-digo-de-detec-o-e-rastreio-de-faces"><a class="anchor" href="#true5-3-an-lise-do-c-digo-de-detec-o-e-rastreio-de-faces"></a>5.3. ANÁLISE DO CÓDIGO DE DETECÇÃO E RASTREIO DE FACES</h3>
<div class="paragraph">
<p>Nessa sessão será discutido a detecção e rastreio de faces dos quadros capturados pela câmera traseira dos dispositivos. Os procedimentos serão apresentados em duas etapas, uma para detecção e outra para o rastreio, pois é dessa forma que o aplicativo funciona. O código para essas operações estão dentro do método <strong>onCameraFrame</strong>.</p>
</div>
<div class="sect3">
<h4 id="true5-3-1-detec-o-de-faces"><a class="anchor" href="#true5-3-1-detec-o-de-faces"></a>5.3.1. DETECÇÃO DE FACES</h4>
<div class="paragraph">
<p>Antes de comentar sobre o código do método <strong>onCameraFrame</strong> é necessário relatar sobre a inicialização da classe abstrata <strong>BaseLoaderCallback</strong>, necessária por prover suporte entre o do gerenciador OpenCV(baixado no Google Play) e o as funções do aplicativo, basicamente essa classe declara um método de retorno para certificar que as bibliotecas do OpenCV estão disponíveis.
Na função <strong>void onManagerConnected(final int)</strong> caso o status seja de sucesso os classificadores Haar e LBP são inicializados(classificadores oferecidos pelo próprio OpenCV), caso haja algum erro de comunicação é emitido mensagem de falha. A imagem abaixo mostra apenas a inicialização do classificador de face(optou-se por classificador do tipo LBP para encontrar as faces por ser mais rápidos apesar de possuir um a taxa de erros um pouco maior), mas em sequência há a inicialização de classificadores de olhos, nariz e boca(esses classificadores são do tipo Haar).</p>
</div>
<div class="imageblock">
<div class="content">
<img src="imagens_final/imag_classificador.jpg" alt="imag classificador.jpg">
</div>
<div class="title">Figure 10. Trecho do código onde os classificadores são inicializados e a esquerda mostra a pasta onde o arquivo se localiza.</div>
</div>
<div class="paragraph">
<p>Voltando ao início do método <strong>onCameraFrame</strong> é possível constatar que as variáveis de quadro colorido e em escala de cinza recebem informações dos frames capturados da variável <strong>inputFrame</strong>. A variável condicionante para detectar faces ou executar o fluxo óptico é <strong>achouFace</strong>. Caso tal variável seja falsa a detecção é iniciada no método void <strong>detectMultiScale(Mat, MatOfRect, double, int, int, Size, Size)</strong> pertencente aos classificadores.</p>
</div>
<div class="paragraph">
<p>Detalhes dos parâmetros:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Mat</strong>: Matriz do tipo CV_8U, contendo a imagem onde os objetos serão detectados.</p>
</li>
<li>
<p><strong>MatOfRect</strong>: Vetor de objetos do tipo retângulo, onde cada um contem um objeto detectado.</p>
</li>
<li>
<p><strong>double</strong>:  Parâmetro de escala, especifica quanto a imagem é reduzida a cada iteração.</p>
</li>
<li>
<p><strong>int</strong>: Especifica a quantidade de retângulos vizinhos que cada candidato deve possui para retê-lo.</p>
</li>
<li>
<p><strong>int</strong>: Representa o método de identificação de objeto em cena(não é usado pelos classificadores novos).</p>
</li>
<li>
<p><strong>Size</strong>: Tamanho mínimo que a imagem pode ter. Abaixo disso são ignoradas.</p>
</li>
<li>
<p><strong>Size</strong>: Tamanho máximo que a imagem deve ter. Acima disso são ignoradas.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Dessa forma o código utilizado para achar faces na imagem em escala de cinza foi o seguinte: <strong>cascade.detectMultiScale(mGray, faces, 1.15, 3, 1, new Size(100, 100)</strong>, new Size(400, 400)). Podemos observar que faces menores que 100 por 100 pixels são ignorados, assim como maiores do que 400 por 400. O número de vizinhos escolhido foi 3 para que sejam reduzidas as detecções de não face. A escala é de 15%(1,15), número suficiente para o processo não ser demasiadamente demorado e não cresça de forma a perder muitas faces.
Os pontos que compõem os retângulos de faces encontradas são armazenadas na função <strong>adicionaPontos(pontos, facesArray[i])</strong>, que os salva na lista de objetos Point chamada pontos. A partir da área das faces encontradas é que são procurados os outros elementos faciais, mas toda a área não é levada em consideração, ela na verdade é reduzida ao retângulo de interesse que é retornada pelo método <strong>Rect redimensionaROI(Rect, int)</strong>, que recebe o retângulo da face e o código representante do elemento de redução(olho, nariz, boca etc). Dessa forma reduz-se esforço computacional e possíveis erros.</p>
</div>
<div class="paragraph">
<p>As reduções do retângulo feitas pelo método para cada código são:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>BOCA</strong>: Para X do P1 mantem o valor do X inicial mais vinte por cento da largura do retângulo vermelho, para o Y usa-se o Y inicial mais sessenta por cento da altura do retângulo vermelho. Para o X do P2 usa-se o X inicial mais oitenta por cento da largura do retângulo vermelho, para o Y do P2 usa-se o Y final do retângulo vermelho.</p>
</li>
<li>
<p><strong>NARIZ</strong>: Para X do P1 mantem o valor do X inicial mais vinte por cento da largura do retângulo vermelho, para o Y usa-se o Y inicial do retângulo vermelho mais vinte e cinco por cento da altura. Para o X do P2 usa-se o X inicial mais oitenta por cento da largura do retângulo vermelho, para o Y do P2 usa-se o Y inicial do retângulo vermelho mais oitenta por cento da altura.</p>
</li>
<li>
<p><strong>OLHOS</strong>: Para X do P1 mantem o valor do X inicial do retângulo vermelho, para o Y usa-se o Y inicial do retângulo vermelho mais vinte por cento da altura. Para o X do P2 usa-se o X final do retângulo vermelho, para o Y do P2 usa-se o Y inicial do retângulo vermelho mais sessenta por cento da altura.</p>
</li>
</ul>
</div>
<div class="imageblock">
<div class="content">
<img src="imagens_final/rosto.jpg" alt="rosto.jpg">
</div>
<div class="title">Figure 11. Trechos de interesse para a procura de elementos. 1- Área de interesse dos olhos; 2- Área de interesse do nariz; 3 - Área de interesse da boca.</div>
</div>
<div class="paragraph">
<p>Após a obtenção dos retângulos de interesse os elementos faciais são encontrados em uma função criada funcional aos 3 elementos chamada <strong>void achaObjetosPorClassificador(Mat, Rect, CascadeClassifier, ArrayList&lt;Point&gt;, int, int, int)</strong>, cujos parâmetros são: a matriz de referência(quadro em escala de cinza), o retângulo de interesse, o classificador a ser utilizado, a lista de pontos a serem armazenados dos retângulos achados, o código informando o que será buscado(nariz, olho, etc), e as configurações de tamanho mínimo em X e Y da imagem. No método há uma contagem para que sejam computados apenas 2 olhos e uma boca e nariz para cada face. Os pontos armazenados são os pontos centrais dos retângulos dos elementos de face, que coincidem com a pupila dos olhos, a ponta do nariz e o centro da boca.
Esse processo de “aprendizagem” se repete por 7 frames afim de que todos os elementos sejam encontrados. A partir do sétimo frame a variável <strong>achouFace</strong> passa a ter valor <strong>true</strong> e a parte do código executada passa a ser o de rastreamento. É possível verificar o trecho do código comentado nessa sessão abaixo.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="imagens_final/codigo_detectMulti.jpg" alt="codigo detectMulti.jpg">
</div>
<div class="title">Figure 12. 1 - Detecção de face; 2 - Adição dos pontos dos elementos do retângulo encontrado; 3 - Funções para encontrar nariz, olhos e boca.</div>
</div>
</div>
<div class="sect3">
<h4 id="true5-3-2-rastreamento-de-faces"><a class="anchor" href="#true5-3-2-rastreamento-de-faces"></a>5.3.2. RASTREAMENTO DE FACES</h4>
<div class="paragraph">
<p>O rastreio é feito quando alguma face é encontrada. Primeiramente há o teste para verificar se todos os elementos das faces foram encontrados(a quantidade de pontos considerada é de 8 pontos para cada face, 4 do bounding box do rosto e 4 dos elementos sociais), caso o resultado do teste seja falso as variáveis <strong>achouFace</strong> e <strong>countFrames</strong> são inicializadas e há uma nova procura por rostos. Caso o resultado seja verdadeiro há o prosseguimento do código com a inicialização da variável <strong>features</strong>, que armazena os pontos encontrados na detecção anterior para serem rastreados. O método que realiza o rastreamento é
<strong>void calcOpticalFlowPyrLK(Mat, Mat, MatOfPoint2f, MatOfPoint2f, MatOfByte, MatOfFloat)</strong>, que o faz usando o algoritmo de Lucas-Kanade através do cálculo do fluxo óptico para um conjunto de pontos esparsos usando o método das pirâmides.</p>
</div>
<div class="paragraph">
<p>Detalhe dos parâmetros:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Mat</strong>: Matriz da imagem anterior.</p>
</li>
<li>
<p><strong>Mat</strong>: Matriz da imagem atual.</p>
</li>
<li>
<p><strong>MatOfPoint2f</strong>: Matriz de pontos em 2d, onde será verificado o fluxo ótico.</p>
</li>
<li>
<p><strong>MatOfPoint2f</strong>: Matriz de pontos em 2d com as novas posições.</p>
</li>
<li>
<p><strong>MatOfByte</strong>: Vetor de Status.</p>
</li>
<li>
<p><strong>MatOfFloat</strong>: Vetor de erros.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Dessa forma o método rastreia onde estão localizados os pontos de feature no quadro atual comparado ao quadro anterior.
O algoritmo construído mostra pontos verdes, que correspondem ao feature atual, e vermelhos mostrando a feature de um quadro anterior. Ligando os pontos existe uma linha vermelha que demonstra o deslocamento dos pontos no espaço.
Ao fim do ciclo, os pontos são checados afim de verificar se o objeto rastreado saiu do frame, em caso positivo as variáveis que decidem a detecção de face são inicializadas com valores que permite novas buscas por rostos.
Na imagem abaixo pode-se observar trecho do código detalhado.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="imagens_final/codigo_tracking.jpg" alt="codigo tracking.jpg">
</div>
<div class="title">Figure 13. Imagem do trecho de código do rastreamento. 1- Método de rastreio, retorna features nas novas posições; 2 - Desenho dos pontos e linhas das features no quadro colorido; 3 - Salvando o quadro atual para serve de quadro anterior na próxima iteração.</div>
</div>
<div class="paragraph">
<p>Ao fim de todas as operações, as posições calculadas dos pontos e retângulos encontrados são úteis para o desenho dos mesmos no quadro colorido, o qual é retornado ao fim do método <strong>onCameraFrame</strong> e por fim mostrado em tela para o usuário.</p>
</div>
<div class="videoblock">
<div class="title">Vídeo explicativo</div>
<div class="content">
<iframe src="https://www.youtube.com/embed/u0EbygiKa1M?rel=0&amp;hl=en" frameborder="0" allowfullscreen></iframe>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="true6-conclus-es"><a class="anchor" href="#true6-conclus-es"></a>6. CONCLUSÕES</h2>
<div class="sectionbody">
<div class="paragraph">
<p>A detecção de faces ocorreu de forma satisfatória e com poucos erros, porém é uma operação com elevado custo computacional, principalmente quando haviam muitos rostos em cena, de tal forma que não serve como fonte rastreadora ainda mais se levado em conta algoritmos que rodam em tempo real. A partir desse pensamento foi de vital importância a inclusão de outro algoritmo para o rastreamento após a detecção dos pontos de face. O algoritmo escolhido foi o de Lucas-Kanade que apesar de eficiente gera erros quando os pixels(features) rastreados se deslocam demasiadamente no espaço entre um quadro e outro. Apesar desses fatores e levando em conta a magnitude do projeto e o tempo necessário para a execução, os resultados foram proveitosos, pois na maioria das situações bem-sucedidas é notória a forma como os algoritmos trabalham juntos para achar e rastrear os rostos. Os erros encontrados, por sua vez, se transformam em cenários de base para possíveis estudos e desenvolvimento na criação de classificadores próprios, que garantem uma quantidade maior de quadros por segundo, ou uma melhor interação entre a câmera nativa e a câmera da biblioteca, assim como tratamento de erros para rastreamento indevido.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="true7-refer-ncias"><a class="anchor" href="#true7-refer-ncias"></a>7. REFERÊNCIAS</h2>
<div class="sectionbody">
<div class="paragraph">
<p>KAPUR, Salil; THAKKAR, Nisarg. Mastering OpenCV Android Application Programming. UK: Packt Publishing, 2015.</p>
</div>
<div class="paragraph">
<p>HOWSE, Joseph. Android Application Programming with OpenCV. UK: Packt Publishing, 2013.
SANTOS, Túlio L. Detecção de faces através do algoritmo de Viola-Jones. COPPE/UFRJ, 2011. Disponível em:<a href="http://http://www.academia.edu/9158427/Detec%C3%A7%C3%A3o_de_faces_atrav%C3%A9s_do_algoritmo_de_Viola-Jones" class="bare">http://http://www.academia.edu/9158427/Detec%C3%A7%C3%A3o_de_faces_atrav%C3%A9s_do_algoritmo_de_Viola-Jones</a>. Acesso em 15 de Junho de 2016.</p>
</div>
<div class="paragraph">
<p>CAMPOS, Filipe M. S de. Detecção e rastreamento de faces em vídeos -  Como detectar faces em vídeos?. Bit a Bit. 2011. Disponível em:<a href="http://http://www.bitabit.eng.br/2011/02/21/como-detectar-faces-em-videos/" class="bare">http://http://www.bitabit.eng.br/2011/02/21/como-detectar-faces-em-videos/</a>. Acesso em 15 de Junho de 2016.</p>
</div>
<div class="paragraph">
<p>WIKIPEDIA. Viola-Jones object detection framework. Wikipedia. Disponível em:<a href="http://https://en.wikipedia.org/wiki/Viola%E2%80%93Jones_object_detection_framework" class="bare">http://https://en.wikipedia.org/wiki/Viola%E2%80%93Jones_object_detection_framework</a>. Acesso em 15 de Junho de 2016.</p>
</div>
<div class="paragraph">
<p>CRUZ, Juliano E. C. Reconhecimento de Objetos em Imagens Orbitais com Uso de Abordagens do Tipo Descritor-Classificador. 2014. 107f. Dissertação de Mestrado em Computação Aplicada - Instituto nacional de Pesquisas Espaciais (INPE), São José dos Campos, 2014.</p>
</div>
<div class="paragraph">
<p>BRITO, Agostinho. Processamento Digital de Imagens. Slide. Departamento de Engenharia da Computação e Automação, Universidade Federal do Rio Grande do Norte, 2016. Disponível em:<a href="http://http://agostinhobritojr.github.io/cursos/pdi/fluxo.pdf" class="bare">http://http://agostinhobritojr.github.io/cursos/pdi/fluxo.pdf</a>. Acesso em 15 de Junho de 2016.</p>
</div>
<div class="paragraph">
<p>AKTHAR, Imran. OpenCV-Android-FaceDectect-GoodFeature. Github, 2013. Disponível em:<a href="http://https://github.com/crankdaworld/OpenCV-Android-FaceDetect-GoodFeature/blob/master/OpenCV-Android-FaceDetect-GoodFeature/face-detection/src/org/opencv/samples/fd/WorkingHeadPose.java" class="bare">http://https://github.com/crankdaworld/OpenCV-Android-FaceDetect-GoodFeature/blob/master/OpenCV-Android-FaceDetect-GoodFeature/face-detection/src/org/opencv/samples/fd/WorkingHeadPose.java</a>. Acesso em 15 de Junho de 2016.</p>
</div>
<div class="paragraph">
<p>GITHUB. Opencv. Github, 2015. Disponível em:<a href="http://https://github.com/Itseez/opencv/blob/master/samples/cpp/lkdemo.cpp" class="bare">http://https://github.com/Itseez/opencv/blob/master/samples/cpp/lkdemo.cpp</a>. Acesso em 15 de Junho de 2016.</p>
</div>
<div class="paragraph">
<p>PUPIL LABS. Pupil - eye tracking platform. Github, 2016. Disponível em:<a href="http://https://github.com/pupil-labs/pupil/blob/master/pupil_src/shared_modules/square_marker_detect.py" class="bare">http://https://github.com/pupil-labs/pupil/blob/master/pupil_src/shared_modules/square_marker_detect.py</a>. Acesso em 15 de Junho de 2016.</p>
</div>
<div class="paragraph">
<p>HOSEK, Roman. Android eye detection and tracking with OpenCV. Disponível em:<a href="http://http://romanhosek.cz/android-eye-detection-and-tracking-with-opencv/" class="bare">http://http://romanhosek.cz/android-eye-detection-and-tracking-with-opencv/</a>. Acesso em 15 de Junho de 2016.</p>
</div>
<div class="paragraph">
<p>ANDROID DEVELOPERS. Api-Guides: App Components. Andorid. Disponível em:&lt;<a href="http://https://developer.android.com/guide/components/index.html" class="bare">http://https://developer.android.com/guide/components/index.html</a></p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="true8-anexos"><a class="anchor" href="#true8-anexos"></a>8. ANEXOS</h2>
<div class="sectionbody">
<div class="paragraph">
<p>O arquivo JAVA pode ser encontrados nesse link: <a href="https://github.com/angelelouise/angelelouise.github.io/blob/master/arquivos/pdi/imagens_final/Arquivos%20principais/Arquivo%20java/FAceDetection.java">Link 1</a></p>
</div>
<div class="paragraph">
<p>O arquivo Manifest nesse link:
<a href="https://github.com/angelelouise/angelelouise.github.io/blob/master/arquivos/pdi/imagens_final/Arquivos%20principais/Arquivo%20manifest/AndroidManifest.xml">Link 1</a></p>
</div>
<div class="paragraph">
<p>Os arquivos de Layout nos links:
<a href="https://github.com/angelelouise/angelelouise.github.io/blob/master/arquivos/pdi/imagens_final/Arquivos%20principais/Arquivos%20layout/activity_face_detection.xml">Link 1</a>
<a href="https://github.com/angelelouise/angelelouise.github.io/blob/master/arquivos/pdi/imagens_final/Arquivos%20principais/Arquivos%20layout/content_face_detection.xml">Link 2</a></p>
</div>
<div class="paragraph">
<p><a href="index.html">Voltar</a></p>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Last updated 2017-03-03 20:35:03 BRT
</div>
</div>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.9.1/styles/github.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.9.1/highlight.min.js"></script>
<script>hljs.initHighlighting()</script>
</body>
</html>